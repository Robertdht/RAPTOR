# ========================================
# AI Model Lifecycle Management Platform
# Environment Configuration File
# Version: 2.0.0
# ========================================

# ========================================
# 資料庫配置 (Database Configuration)
# ========================================

# PostgreSQL 資料庫設定 - MLflow 後端存儲
POSTGRES_USER=mlflow
POSTGRES_PASSWORD=mlflow
POSTGRES_DB=mlflow
POSTGRES_PORT=5432

# ========================================
# LakeFS / S3 儲存配置
# ========================================

# LakeFS S3-Compatible Gateway Configuration
MLFLOW_S3_ENDPOINT_URL=http://192.168.157.165:8011 # lakeFS endpoint
AWS_ACCESS_KEY_ID=AKIAJMKCJPEEN45R5WQQ         # lakeFS access key
AWS_SECRET_ACCESS_KEY=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 # lakeFS secret key

# LakeFS 儲存命名空間
LAKEFS_MODEL_STORAGE_NAMESPACE=s3://lakefs/models
LAKEFS_DATASET_STORAGE_NAMESPACE=s3://lakefs/datasets

# ========================================
# MLflow 配置 (MLflow Configuration)
# ========================================

# MLflow 服務器配置
MLFLOW_TRACKING_URI=http://mlflow:5555 # 在 Docker Compose 網路中使用服務名稱
MLFLOW_HOST=0.0.0.0
MLFLOW_PORT=5555

# MLflow version (e.g., v3.3.0)
MLFLOW_VERSION=v3.3.2

# MLflow 後端存儲配置  
# MLflow Server
MLFLOW_BACKEND_STORE_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}


# MLflow Artifact 存儲配置
#MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://lakefs

# ========================================
# 外部服務配置 (External Services)
# ========================================

# Hugging Face Token - 用於下載模型
HF_TOKEN=YOUR_HF_TOKEN

# Ollama API 配置
# 開發環境：使用主機 IP
OLLAMA_API_BASE=http://192.168.157.165:11434

# 生產環境（Docker 內部訪問）：使用 host.docker.internal
# OLLAMA_API_BASE=http://host.docker.internal:11434

# ========================================
# FastAPI 應用配置 (FastAPI Configuration)
# ========================================

# 基本服務配置
FASTAPI_HOST=192.168.157.165
FASTAPI_PORT=8009

# 開發/生產模式配置
FASTAPI_DEBUG=true
FASTAPI_RELOAD=true
FASTAPI_WORKERS=1

# 日誌配置
LOG_LEVEL=INFO

# ========================================
# GPU / 硬體資源配置 (Hardware Configuration)
# ========================================

# GPU 配置
NVIDIA_VISIBLE_DEVICES=all
# 記憶體限制（MB）
# MAX_MODEL_MEMORY_MB=4096
# INFERENCE_BATCH_SIZE=1

# ========================================
# 網路和安全配置 (Network & Security)
# ========================================

# Nginx 配置（生產環境）
NGINX_HTTP_PORT=80
NGINX_HTTPS_PORT=443

# API 限流配置
API_RATE_LIMIT=100
API_RATE_LIMIT_PERIOD=60

# JWT 密鑰（如果啟用認證）
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# CORS 配置
CORS_ORIGINS=* # 允許所有來源，生產環境中請根據需求設置具體域名
CORS_CREDENTIALS=true # 允許攜帶憑證
CORS_METHODS=* # 允許所有 HTTP 方法
CORS_HEADERS=* # 允許所有標頭

# ========================================
# 監控和日誌配置 (Monitoring & Logging)
# ========================================

# Prometheus 監控（可選）
PROMETHEUS_PORT=9091
GRAFANA_PORT=3000

# 日誌設定
LOG_FORMAT=json
LOG_FILE_PATH=/app/logs/aimodel.log
LOG_MAX_SIZE_MB=100
LOG_BACKUP_COUNT=5

# ========================================
# 開發和測試配置 (Development & Testing)
# ========================================

# 開發模式設定
DEVELOPMENT_MODE=true
TEST_MODE=false

# 測試資料庫（如果需要）
TEST_DATABASE_URL=sqlite:///./test.db

# ========================================
# 功能開關 (Feature Flags)
# ========================================

# 啟用/停用功能
ENABLE_GPU_MONITORING=true
ENABLE_MODEL_CACHING=true
ENABLE_DISTRIBUTED_INFERENCE=false
ENABLE_AUTHENTICATION=false
ENABLE_RATE_LIMITING=true

# 實驗性功能
EXPERIMENTAL_FEATURES=false

