import os
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import Optional, List
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, MatchAny
from sentence_transformers import SentenceTransformer
import uvicorn
import time
from functools import wraps
from cache_manager import CacheManager
from qdrant_client import AsyncQdrantClient

class SearchRequest(BaseModel):
    """æœç´¢è«‹æ±‚æ¨¡å‹"""
    query_text: str = Field(..., description="æœç´¢é—œéµå­—", min_length=1)
    embedding_type: str = Field(..., description="æœç´¢é¡å‹: summary æˆ– text")
    type: Optional[str] = Field(None, description="é›†åˆé¡å‹: audio/video/document/image")
    filename: Optional[List[str]] = Field(None, description="æ–‡ä»¶ååˆ—è¡¨")
    source: Optional[str] = Field(None, description="åœ–åƒæ ¼å¼: jpg/png/jpeg/gif/bmp ç­‰")
    limit: int = Field(5, description="è¿”å›çµæœæ•¸é‡", ge=1, le=100)

class SearchResult(BaseModel):
    """å–®å€‹æœç´¢çµæœ"""
    score: float
    id: str
    payload: dict

class SearchResponse(BaseModel):
    """æœç´¢éŸ¿æ‡‰æ¨¡å‹"""
    success: bool
    total: int
    results: List[SearchResult]

class IndexResponse(BaseModel):
    """ç´¢å¼•æ“ä½œéŸ¿æ‡‰"""
    success: bool
    message: str
    indexes: Optional[dict] = None


app = FastAPI(
    title="åœ–åƒç›¸ä¼¼åº¦æœç´¢ API",
    description="åŸºæ–¼ Qdrant çš„åœ–åƒå…§å®¹ç›¸ä¼¼åº¦æœç´¢æœå‹™",
    version="1.0.0"
)

client = None
model = None
collection_name = "images"

cm = CacheManager(
    host='192.168.157.165',
    port=7000,
    password="dht888888",
    max_connections=1000,
    ttl=3600,
    ttl_multiplier=1e-2,
    is_cluster=True
)

@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•æ™‚åˆå§‹åŒ–"""
    global client, model
    
    qdrant_host = os.getenv("QDRANT_HOST", "localhost")
    qdrant_port = int(os.getenv("QDRANT_PORT", "6333"))
    
    print(f"ğŸ”Œ æ­£åœ¨é€£æ¥ Qdrant ({qdrant_host}:{qdrant_port})...")
    client = AsyncQdrantClient(host=qdrant_host, port=qdrant_port)
    
    try:
        collection_info = client.get_collection(collection_name)
        print(f"âœ… Collection '{collection_name}' å·²å­˜åœ¨")
        print(f"   - å‘é‡æ•¸é‡: {collection_info.vectors_count}")
        print(f"   - é»æ•¸é‡: {collection_info.points_count}")
    except Exception as e:
        print(f"âš ï¸  Collection '{collection_name}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨å‰µå»º...")
        try:
            from qdrant_client.models import VectorParams, Distance
            
            client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(
                    size=1024,  
                    distance=Distance.COSINE
                )
            )
            print(f"âœ… æˆåŠŸå‰µå»º collection: {collection_name}")
            
            index_fields = [
                ("embedding_type", "keyword"),
                ("type", "keyword"),
                ("filename", "keyword"),
                ("status", "keyword"),
            ]
            
            if collection_name in ["videos", "audios"]:
                index_fields.append(("speaker", "keyword"))
            elif collection_name in ["images", "documents"]:
                index_fields.append(("source", "keyword"))
            
            print(f"ğŸ“Š æ­£åœ¨å‰µå»ºç´¢å¼•...")
            for field_name, field_type in index_fields:
                try:
                    client.create_payload_index(
                        collection_name=collection_name,
                        field_name=field_name,
                        field_schema=field_type
                    )
                    print(f"   âœ… ç´¢å¼• '{field_name}' å‰µå»ºæˆåŠŸ")
                except Exception as idx_err:
                    if "already exists" in str(idx_err).lower():
                        print(f"   â„¹ï¸  ç´¢å¼• '{field_name}' å·²å­˜åœ¨")
                    else:
                        print(f"   âš ï¸  ç´¢å¼• '{field_name}' å‰µå»ºå¤±æ•—: {idx_err}")
            
        except Exception as create_err:
            print(f"âŒ å‰µå»º collection å¤±æ•—: {create_err}")
            raise
    
    print("ğŸ¤– æ­£åœ¨è¼‰å…¥å‘é‡æ¨¡å‹ (BAAI/bge-m3)...")
    model = SentenceTransformer("BAAI/bge-m3")
    print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
    print(f"ğŸš€ {collection_name} æœç´¢æœå‹™å·²å°±ç·’ï¼")

@app.get("/", tags=["ç³»çµ±"])
async def root():
    """API æ ¹è·¯å¾‘"""
    return {
        "message": "åœ–åƒç›¸ä¼¼åº¦æœç´¢ API",
        "version": "1.0.0",
        "docs": "/docs",
        "collection": collection_name
    }


@app.get("/health", tags=["ç³»çµ±"])
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    try:
        collection_info = client.get_collection(collection_name)
        return {
            "status": "healthy",
            "collection": collection_name,
            "vectors_count": collection_info.vectors_count,
            "points_count": collection_info.points_count
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"æœå‹™ä¸å¯ç”¨: {str(e)}")


@cm.cache
def cached_search(collection_name, query_vector, query_filter, limit):
    """å…·å¿«å–çš„ Qdrant æœå°‹"""
    results = client.search(
        collection_name=collection_name,
        query_vector=query_vector,
        query_filter=query_filter,
        limit=limit,
        with_payload=True,
        with_vectors=False
    )
    return results


def build_filter(
    embedding_type: str,
    type_value: Optional[str] = None,
    filenames: Optional[List[str]] = None,
    source: Optional[str] = None
) -> Optional[Filter]:
    """å»ºç«‹ç¯©é¸æ¢ä»¶"""
    must_conditions = []
    must_conditions.append(FieldCondition(key="status", match=MatchValue(value="active")))
    must_conditions.append(FieldCondition(key="embedding_type", match=MatchValue(value=embedding_type)))
    
    if type_value:
        must_conditions.append(FieldCondition(key="type", match=MatchValue(value=type_value)))
    
    if filenames:
        if len(filenames) == 1:
            must_conditions.append(FieldCondition(key="filename", match=MatchValue(value=filenames[0])))
        else:
            must_conditions.append(FieldCondition(key="filename", match=MatchAny(any=filenames)))
    
    if source:
        must_conditions.append(FieldCondition(key="source", match=MatchValue(value=source)))
    
    return Filter(must=must_conditions) if must_conditions else None


@app.post("/image_search", response_model=SearchResponse, tags=["æœç´¢"])
async def search_images(request: SearchRequest):
    """åŸ·è¡Œåœ–åƒç›¸ä¼¼åº¦æœç´¢ (æ”¯æ´ Redis å¿«å–)"""
    try:
        start = time.perf_counter()

        if request.embedding_type not in ["summary", "text"]:
            raise HTTPException(status_code=400, detail="embedding_type å¿…é ˆæ˜¯ 'summary' æˆ– 'text'")
        
        query_filter = build_filter(
            embedding_type=request.embedding_type,
            type_value=request.type,
            filenames=request.filename,
            source=request.source
        )
        
        query_vector = model.encode(request.query_text).tolist()
        
        results = cached_search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=query_filter,
            limit=request.limit
        )
        
        formatted_results = [
            SearchResult(score=res.score, id=str(res.id), payload=res.payload)
            for res in results
        ]

        end = time.perf_counter()
        print(f"[TIMED] /image_search took {end - start:.3f}s")

        return SearchResponse(success=True, total=len(formatted_results), results=formatted_results)
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±æ•—: {str(e)}")


@app.post("/indexes/create", response_model=IndexResponse, tags=["ç´¢å¼•ç®¡ç†"])
async def create_indexes():
    """å»ºç«‹æ‰€æœ‰å¿…è¦çš„ç´¢å¼•"""
    try:
        index_fields = [
            ("embedding_type", "keyword"),
            ("type", "keyword"),
            ("filename", "keyword"),
            ("source", "keyword"),
        ]
        created, existing, errors = [], [], []
        for field_name, field_type in index_fields:
            try:
                client.create_payload_index(
                    collection_name=collection_name,
                    field_name=field_name,
                    field_schema=field_type
                )
                created.append(field_name)
            except Exception as e:
                if "already exists" in str(e).lower():
                    existing.append(field_name)
                else:
                    errors.append(f"{field_name}: {str(e)}")
        return IndexResponse(
            success=len(errors) == 0,
            message=f"å»ºç«‹ {len(created)} å€‹æ–°ç´¢å¼•ï¼Œ{len(existing)} å€‹å·²å­˜åœ¨",
            indexes={"created": created, "existing": existing, "errors": errors}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å»ºç«‹ç´¢å¼•å¤±æ•—: {str(e)}")


@app.get("/indexes", response_model=IndexResponse, tags=["ç´¢å¼•ç®¡ç†"])
async def get_indexes():
    """æŸ¥çœ‹ç¾æœ‰ç´¢å¼•"""
    try:
        collection_info = client.get_collection(collection_name)
        indexes = {}
        if collection_info.payload_schema:
            indexes = {field: str(schema) for field, schema in collection_info.payload_schema.items()}
        return IndexResponse(success=True, message=f"æ‰¾åˆ° {len(indexes)} å€‹ç´¢å¼•", indexes=indexes)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç²å–ç´¢å¼•å¤±æ•—: {str(e)}")


@app.get("/collection/info", tags=["é›†åˆç®¡ç†"])
async def get_collection_info():
    """ç²å– collection è©³ç´°è³‡è¨Š"""
    try:
        info = client.get_collection(collection_name)
        return {
            "name": collection_name,
            "vectors_count": info.vectors_count,
            "points_count": info.points_count,
            "status": info.status,
            "config": {
                "vector_size": info.config.params.vectors.size if hasattr(info.config.params, 'vectors') else None,
                "distance": str(info.config.params.vectors.distance) if hasattr(info.config.params, 'vectors') else None
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç²å–è³‡è¨Šå¤±æ•—: {str(e)}")


if __name__ == "__main__":
    uvicorn.run(
        "api_image_search_with_cache:app",
        host="0.0.0.0",
        port=8814,
        reload=True
    )
